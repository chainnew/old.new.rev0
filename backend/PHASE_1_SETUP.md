# Phase 1 Setup Guide: Synergy Systems

**Status**: Phase 1 Complete (17/50 â†’ 35/50)
**Duration**: ~15 minutes setup

This guide walks through setting up the Phase 1 synergy improvements:
- OpenTelemetry distributed tracing
- Orchestration monitor (self-healing)
- Stack inference engine (pgvector)

---

## Prerequisites

- âœ… Python 3.13 (or 3.11+)
- âœ… PostgreSQL 16 running
- âœ… OpenRouter API key in `.env`
- âœ… Virtual environment activated

---

## Step 1: Install Dependencies (2 min)

```bash
# From project root
cd backend

# Install new packages (OTel + pgvector)
pip install -r requirements.txt

# Verify OTel installed
python -c "from opentelemetry import trace; print('OTel OK')"
```

**Expected Output**:
```
OTel OK
```

---

## Step 2: Set Up pgvector (3 min)

### 2A. Check PostgreSQL Connection

```bash
# Test connection (update credentials if needed)
psql -d hive_mind -U postgres -c "SELECT version();"
```

**Expected**: PostgreSQL 16.x version output

### 2B. Run Migration

```bash
# Create pgvector extension + stack_templates table
psql -d hive_mind -U postgres -f migrations/001_add_pgvector.sql
```

**Expected Output**:
```sql
CREATE EXTENSION
CREATE TABLE
CREATE INDEX
...
       title        |    kind     | num_tags | embedding_dims
--------------------+-------------+----------+----------------
 Django + Vue       | fullstack   |        3 |           1536
 FastAPI + React    | fullstack   |        3 |           1536
 MERN Stack         | fullstack   |        3 |           1536
 Supabase Starter   | serverless  |        4 |           1536
 T3 Stack           | fullstack   |        3 |           1536
(5 rows)
```

### 2C. Seed Embeddings (One-Time, ~2 min)

```bash
# Generate real embeddings for stack templates
python analyzers/stack_inferencer.py --seed-embeddings
```

**Expected Output**:
```
ðŸŒ± Seeding embeddings for stack templates...
   Found 5 templates

   [1/5] Embedding: MERN Stack
   [2/5] Embedding: T3 Stack
   [3/5] Embedding: FastAPI + React
   [4/5] Embedding: Django + Vue
   [5/5] Embedding: Supabase Starter

âœ… Embeddings seeded successfully!
```

---

## Step 3: Test Stack Inference (1 min)

```bash
# Run test inferences with sample scopes
python analyzers/stack_inferencer.py --test
```

**Expected Output**:
```
ðŸ§ª Testing stack inference...

[1] Scope: Build a todo app with Python backend and modern UI
    Backend: Python/FastAPI
    Frontend: React + Vite + TanStack Query
    Confidence: 0.85
    Matched: FastAPI + React
    Rationale: Async Python APIs with FastAPI. React for modern UI...

[2] Scope: E-commerce store with real-time inventory and Stripe payments
    Backend: Python/FastAPI
    Frontend: Next.js 14
    Confidence: 0.78
    Matched: FastAPI + React
    ...
```

**âœ… Success**: Confidence >0.7 means templates are working!

---

## Step 4: Initialize Orchestration Monitor (2 min)

### 4A. Create Events Table

The monitor auto-creates the `orchestration_events` table on first run, but verify:

```bash
# Check if table exists
psql -d hive_mind -U postgres -c "\dt orchestration_events"
```

**Expected**: Table listing (or "relation does not exist" - will be created next)

### 4B. Test Monitor (Dry Run)

```bash
# Run monitor for 30s (Ctrl+C to stop)
timeout 30 python orchestration_monitor.py
```

**Expected Output**:
```
ðŸ”„ Orchestration Monitor initialized
   ðŸ“ Database: swarms/active_swarm.db
   â±ï¸  Poll interval: 10s
   ðŸ” Max retries: 3 with exponential backoff

âœ… orchestration_events table ready
ðŸš€ Starting orchestration monitor loop...

ðŸ” Found 0 failed tasks (iteration 1)
ðŸ” Found 0 failed tasks (iteration 2)
...

ðŸ“Š Swarm Health (iteration 3):
   Tasks by status: {'pending': 12, 'in-progress': 2}
   Recent interventions: 0
   Retry success rate: 100.0%
```

**Note**: No failed tasks is normal for fresh DB. We'll test retries in Step 6.

---

## Step 5: Test OpenTelemetry Tracing (3 min)

### 5A. Start Swarm API with Tracing

```bash
# Start FastAPI with OTel (console exporter)
python swarm_api.py
```

**Expected Output**:
```
âœ… OpenTelemetry initialized for grok-orc-orchestrator
   ðŸ“Š Traces: Console (demo mode)
   ðŸ“ˆ Metrics: Console (10s interval)
ðŸš€ Starting Hive-Mind Swarm API...
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 5B. Trigger Traced Request

In another terminal:

```bash
# Create a test swarm (triggers tracing)
curl -X POST http://localhost:8000/orchestrator/process \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Build a task management app with Next.js",
    "user_id": "test_user"
  }'
```

**Expected Console Output** (in swarm_api terminal):
```
{
  "name": "orchestrator.process_message",
  "context": {
    "trace_id": "0x1a2b3c4d...",
    "span_id": "0x5e6f7g8h...",
  },
  "attributes": {
    "user.id": "test_user",
    "message.length": 48,
    "swarm.id": "abc123-...",
    "swarm.status": "success",
    "plan.num_agents": 3,
    "plan.total_tasks": 12
  },
  "events": [],
  "status": {"status_code": "OK"}
}
```

**âœ… Success**: Span shows `swarm.id` and `plan.num_agents`!

---

## Step 6: Test Self-Healing Retry (5 min)

### 6A. Start Monitor in Background

```bash
# Run monitor as daemon (logs to file)
nohup python orchestration_monitor.py > monitor.log 2>&1 &

# Get PID for later
echo $! > monitor.pid
```

### 6B. Simulate Failed Task

```bash
# Insert a fake failed task into DB
sqlite3 swarms/active_swarm.db << EOF
INSERT INTO tasks (id, agent_id, swarm_id, description, status, data, priority, created_at, updated_at)
VALUES (
  'test-failed-task-001',
  'agent-test-001',
  'swarm-test-001',
  'Test failed task for retry demo',
  'failed',
  '{}',
  10,
  datetime('now'),
  datetime('now')
);
EOF

echo "âœ… Fake failed task inserted"
```

### 6C. Watch Monitor Logs

```bash
# Tail logs (should see retry within 10-20s)
tail -f monitor.log
```

**Expected Output**:
```
ðŸ” Found 1 failed tasks (iteration 3)
ðŸ” Retrying task test-fai (attempt 1/3)
   â³ Backoff: 10s
   ðŸ“ Test failed task for retry demo...
âœ… Task test-fai re-queued for execution
```

### 6D. Verify Event Logged

```bash
# Check orchestration_events table
sqlite3 swarms/active_swarm.db \
  "SELECT event_type, details FROM orchestration_events ORDER BY timestamp DESC LIMIT 1;"
```

**Expected**:
```
retry|Retry #1 after 10.0s backoff
```

### 6E. Stop Monitor

```bash
# Kill background monitor
kill $(cat monitor.pid)
rm monitor.pid monitor.log
```

**âœ… Success**: Monitor auto-retried failed task!

---

## Step 7: Verify All Systems (1 min)

```bash
# Run quick health check
python << 'EOF'
# Test imports
from telemetry import get_tracer
from orchestration_monitor import OrchestrationMonitor
from analyzers.stack_inferencer import infer_stack

# Test stack inference
result = infer_stack("Build a blog with Django")
print(f"âœ… Stack Inference: {result['backend']} (confidence: {result['confidence']:.2f})")

# Test tracer
tracer = get_tracer()
with tracer.start_as_current_span("test_span"):
    print("âœ… OpenTelemetry: Tracer OK")

# Test monitor
monitor = OrchestrationMonitor()
print("âœ… Orchestration Monitor: DB connection OK")

print("\nðŸŽ‰ All Phase 1 systems operational!")
EOF
```

**Expected Output**:
```
âœ… Stack Inference: Python/Django (confidence: 0.82)
âœ… OpenTelemetry: Tracer OK
âœ… Orchestration Monitor: DB connection OK

ðŸŽ‰ All Phase 1 systems operational!
```

---

## Troubleshooting

### Issue: pgvector extension fails

**Error**: `ERROR: extension "vector" does not exist`

**Fix**:
```bash
# Install pgvector (macOS with Homebrew)
brew install pgvector

# Restart PostgreSQL
brew services restart postgresql@16
```

### Issue: OpenRouter API key not found

**Error**: `ValueError: OPENROUTER_API_KEY not found`

**Fix**: Add to `.env` file:
```bash
OPENROUTER_API_KEY=sk-or-v1-...
```

### Issue: OTel spans not showing

**Fix**: Ensure you're looking at the **swarm_api.py terminal output**, not the curl response. Spans print to stdout.

---

## Next Steps

**Week 1 Completion** (Tomorrow):
1. [ ] Set up Grafana + Prometheus (Docker Compose)
2. [ ] Integrate `infer_stack()` into orchestrator
3. [ ] Add handoff latency metrics

**Week 2** (Next Monday):
1. [ ] Temporal SDK integration
2. [ ] Parallel agent workflows
3. [ ] Dynamic stack selection in planner

See [`docs/SYNERGY_ROADMAP.md`](../docs/SYNERGY_ROADMAP.md) for full plan.

---

## Files Added (Phase 1)

**Core**:
- `backend/telemetry.py` - OTel initialization
- `backend/orchestration_monitor.py` - Self-healing loop
- `backend/analyzers/stack_inferencer.py` - pgvector inference

**Database**:
- `backend/migrations/001_add_pgvector.sql` - Schema + seed data

**Documentation**:
- `docs/SYNERGY_ROADMAP.md` - 4-week roadmap
- `backend/PHASE_1_SETUP.md` - This guide

**Updated**:
- `backend/requirements.txt` - Added OTel packages
- `backend/swarm_api.py` - OTel tracing integration

---

**Setup Time**: ~15 minutes
**Status**: Phase 1 Complete âœ…
**Score**: 35/50 (from 17/50)
